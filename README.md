This project focuses on performing image-to-image (I2I) style translation, specifically converting clear images into synthetic foggy images. The goal is to contribute to the machine learning (ML) research community, particularly in the autonomous vehicle (AV) industry, which lacks sufficient datasets depicting adverse weather conditions, such as foggy environments. By generating synthetic foggy images, this project aims to enhance the robustness of AV models in fog-related scenarios.

The project employs the CycleGAN architecture to carry out the I2I translation, as CycleGAN is well-suited for unpaired datasets and enables the transformation of clear images to foggy ones without the need for paired training data. The model is trained and tested on standard image datasets, leveraging the cloud computing resources of Google Colab.

DATASET : 
  - For Clean images : TT100K Dataset
  - For Foggy images : CityScape Dataset

This project highlights the potential of using CycleGAN for image-to-image translation in the AV industry. By generating synthetic foggy images from clear images, we focus on the underexplored area of adverse weather conditions. Though the model works there is still need for improvement in terms of the quality of the image produced by the Model. To enhance the quality of the image further Hybrid models may be utilised.

USEFUL LINKS :
  - Dataset used : https://drive.google.com/drive/folders/114tanwq-fgK2ungb-umbOJBHDJRMMvAg?usp=drive_link
  - Output : https://drive.google.com/drive/folders/1ctzVcdTB79Q21GCjm8ll1UCUnqLn7Gbj?usp=sharing

OUTPUT : 
![10100](https://github.com/user-attachments/assets/f3472d1a-8f96-458b-8e43-e61038ab12f3)
